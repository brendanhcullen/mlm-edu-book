[
["index.html", "Multilevel Modeling in R with Application in Educational Research 1 Preface", " Multilevel Modeling in R with Application in Educational Research Daniel Anderson Joshua Rosenburg 2020-09-22 1 Preface I like multilevel modeling a lot. I wrote a pimer on it years ago. This is an update to that. But this time we’re doing everything in R and it will all be reproducible. "],
["introduction.html", "2 Introduction", " 2 Introduction Hierarchical linear modeling (HLM) is a powerful and flexible statistical framework for analyzing complex nested relationships. In education, for example, we may be interested in factors that affect student achievement. Broadly, we may theorize factors associated with the school (school social groups, principal leadership, school size), the teachers (effectiveness of the teacher, specific expertise of the teacher, relationship of the teacher with the student), and the students themselves (motivation, previous achievement, general intelligence). Each of these factors associated with student achievement could be conceptualized as different “levels” of nesting – students (at Level 1) are nested within classrooms (at Level 2), which are nested within schools (at Level 3) – in which each level potentially impacts student achievement. HLM allows researchers to investigate these nested relationships and either parse them out (i.e., control for higher-level factors to examine the unique effect of a specific variable) or examine the impact of variables at the higher levels (e.g., the effect of attending public versus private school on student achievement). HLM is used across a variety of disciplines to examine multilevel effects. For example, in organizational research one may investigate how employee interactions differ by the type of organization the employees belong to (e.g., corporate compared to local). In this paper, however, I will be focusing exclusively on the application of HLM to educational research. HLM is particularly well suited for evaluating changes in student achievement through growth models applied to longitudinal data. These growth models can be used to evaluate how individuals are changing over time, and how specific variables at any level predict where the individuals begin and/or the rate at which they change. For example, we could examine data from a cohort of students as they moved from kindergarten through grade 5 in urban and rural schools. We could then test whether the achievement of students attending urban schools differed significantly in kindergarten from students attending rural schools, and whether these same students differed in the rate at which they progressed during the 5 years of the study. We could also examine other characteristics of the students. For example, we could examine the rate at which students with one specific disability (e.g., autism spectrum disorder) progressed as compared to students with a different disability (e.g., learning disabled), and whether this observed relationship held for students in both urban and rural schools. Growth models are discussed in Chapter 3 of this manuscript, while cross-sectional models (i.e., one point in time) are discussed in Chapter 2. The purpose of this paper is to introduce readers to the core concepts of HLM as applied to cross-sectional and longitudinal data. HLM is a complex topic and no assumptions are made about readers’ familiarity with the topic outside of a basic understanding of regression. Thus, the bulk of this paper is dedicated to interpreting HLM analyses and important decisions that analysts make when building complex models. In Chapter 2, I begin with a brief explanation of nested data structures and some of the problems they pose. The primary components of a two-level model with cross-sectional data are then introduced and important elements of consideration discussed. In this section, the basic notation used for the null or unconditional model (no predictor variables) is introduced, as well as how it can be extended to include predictor variables. Model building and important statistics accompanying HLM analyses are also discussed, including overall model fit, the intraclass correlation coefficient (ICC), and the Pseudo R2 statistic. All the basic concepts of HLM are introduced in this section, which is concluded with an illustrated example using real data. The bulk of the paper is dedicated to Chapter 3, where the principles introduced for cross-sectional data are extended to illustrate how the concept of nesting can be used to measure growth by treating time as nested within a student. In other words, just as many students may be nested within a school in a model with cross-sectional data, so too can multiple test scores be nested within an individual with longitudinal data. A two-level growth model is first introduced. It is then shown how the notation and model-building strategies can be expanded to three-levels. Considerable time is taken in Chapter 3 to reflect on specific issues related to growth modeling, including the linearity of the slope, the coding of time, and covariates that may vary by time. It is important to note that this paper is intended to be educative for consumers of research – not for researchers intending to apply the techniques. However, HLM notation is discussed in considerable detail given that it is critical to understanding the specific model that has been applied. As stated earlier, it is also assumed that readers have a basic understanding of regression. For readers not yet familiar with regression, I recommend reading the first two sections of the structural equation modeling manuscript from this series (Anderson, Patarapichayatham, &amp; Nese, 2013). Because the intended audience of this paper is consumers of research, and not researchers, there will be some issues that will be covered in less depth than interested readers may prefer. For those interested in more detailed accounts of the topics presented here, I recommend Raudenbush and Bryk (2002), Hox (2010), and (Snijders &amp; Bosker, 2011) for a comprehensive overview of HLM and Singer and Willett (2003) for more detail surrounding analyses with longitudinal data. Finally, it is worth mentioning that readers completely unfamiliar with HLM may not follow every detail of the illustrated examples. One should not be concerned if this is the case. I opted to be overly inclusive in the examples, rather than gloss over important elements of the analysis, reasoning that more advanced readers may be interested in the model building decisions. "],
["basic-concepts.html", "3 Basic Concepts", " 3 Basic Concepts In contexts where data are nested (e.g., students nested within schools) and the effect of predictor variables on some outcome depend on that nesting, it is important that the nesting be accounted for in the model to avoid misrepresenting the effects. In many cases, individuals nested within some higher-level unit are more similar to each other than they are different and the observed effect of some treatment may then depend, in part, upon their membership to a specific higher-level unit (e.g., students attending School A instead of School B). If the data are dependent upon the higher-level unit then the residuals of individuals within the unit will be correlated – violating the independence of observations assumption of standard single-level regression (Raudenbush &amp; Bryk, 2002). As Roberts (2004) showed, not accounting for nested structures may potentially have dramatic effects and can even reverse the fundamental findings of the study. Roberts used a composite variable called “urbanicity” to predict students’ science achievement. Without accounting for the nesting there was a .77 correlation, indicating that as students’ urbanicity score increased, their science achievement generally did as well. This finding was puzzling and counter to previous research (e.g., Hannaway &amp; Talbert, 1993). However, by accounting for the nesting of students within schools, the correlation became -.81, implying that as students’ urbanicity increased their science achievement generally decreased. The reversal of the observed effect was found because within each school the correlation was negative, but by ignoring the context of the school the correlation “looked” positive. Generally, accounting for nesting does not produce as dramatic results as those shown by Roberts, but it serves as a good reminder for why accounting for nesting is so important. Not accounting for nested data structures generally leads to aggregation bias, misestimated standard errors, and heterogeneity of regression (Raudenbush &amp; Bryk, 2002). Aggregation bias occurs when a variable takes on a different meaning in its aggregated form than it does in its disaggregated form. When entering the aggregated variable into the model as a predictor variable it may then bias the results toward the aggregated meaning of the variable. As Raudenbush and Bryk highlight, for example, the overall composition of a school’s student population (e.g., percent of students eligible for free or reduced price lunch; FRL) may have an effect on individual students beyond the effect of individual FRL eligibility. As will be discussed later in the paper, HLM can readily handle these complex relationships. Misestimated standard errors occur when we fail to account for the dependence upon the higher-level units – i.e., when the independence of observations assumption is violated. HLM corrects the estimation by including the higher-level units in the model so that observations within a unit are independent. Heterogeneity of regressions occurs when the relation between a predictor variable and a specific outcome vary by some higher-level unit. For example, perhaps in some schools the relation between FRL and student achievement is quite strong while in others it is considerably weaker. Standard single-level regression would ignore this heterogeneity and assume the relation is constant across schools, while HLM can explicitly test and account for the heterogeneous relationships. Two-Level Models In this section I begin by providing an overview of the notation used in HLM for a two-level model. I then move to a section on model building. Model building in HLM must be systematic and theoretically based. The complexity of the models necessitate careful consideration of each decision made so the final model makes sound theoretical sense and the analyst does not “overfit” the model to the specific sample he or she has attained. Notation The notation for all HLM models can be displayed in two ways: by the level of analysis, or in a single equation called a “mixed model”. Models that are not terribly complex are often displayed as a single equation. However, as the models become more complicated it is often helpful to have the equations separated by the level of analysis. Equation 2.1 below details a basic two-level HLM model with no predictor variables, displayed by level. $$ Y_{ij}={0j} + r{ij} {0j} = {00} + u_{0j} $$ At level 1, Y_ij represents the outcome Y for level one unit i nested in level two unit j, and is equal to a level one intercept, β_0j, and residual or unexplained variance r_ij. At level 2, the level 1 intercept, β_0j, is set as the outcome in a new regression equation with two components: the level 2 intercept, γ_00, and a random parameter, u_0j, which is the level 2 residual variance. The level 2 random parameter, u_0j, is what allows the model to vary by the higher-level unit. Equation 2.1 can also be displayed in its mixed model form, by simply substituting the level 2 equation into the level 1 equation. We then obtain: Y_ij=γ_00+〖u_0j+r〗_ij (2.2) Note that Equation 2.2 represents the same model as Equation 2.1, but as a single equation. The β_0j term has now dropped out of the model given that it is defined by γ_00+u_0j. In other words, Equation 2 simply represents the substitution of β_0j with the higher-level terms that define it. To better illustrate what these terms mean we can utilize a typical example in education – students nested within schools. We can use HLM to control for this nesting and more accurately examine the effects of specific predictor variables on an outcome. For instance, say we were interested in the math achievement of students. Equation 2.2 then becomes 〖Math〗_ij=γ_00+〖u_0j+r〗_ij (2.3) Note that all that has changed at this point is that the outcome Y_ij has been substituted with 〖Math〗_ij. However, now that we have some context of a problem we can better define what the terms mean. In this model, the math achievement of student i nested in school j is equal to the average achievement of schools (i.e., school level intercept), γ_00, plus the random component related to the school the student attends, u_0j (i.e., the difference between the overall average school achievement and average achievement for school j, the school the student attends), plus residual variance unique to the student and not captured by the model, r_ij. The r_ij term includes all the “left over” variance in the model, and includes measurement error, unaccounted for variables in the model, or potentially a host of other factors. The random component u_0j is what differentiates HLM from standard single-level regression because it allows the intercepts of schools to vary, whereas in single-level regression only one intercept would be calculated and assumed fixed, or equal, across schools. HLM relaxes this assumption, and allows school intercepts to vary randomly (in other words, the intercepts are freely estimated). Predictor variables can also be added to the model at level 1, level 2, or both. Adding one predictor to each level results in the following model Y_ij=β_0j+β_1j X_ij+r_ij (2.4) β_0j=γ_00+γ_01 W_j+u_0j β_1j=γ_10+γ_11 W_j+u_1j Where X_ij represents a predictor variable for individual i nested in level 2 unit j, and W_j represents a predictor variable for level 2 unit j. Note that for each new predictor added to the model at level 1 we get a new beta at level 2 that is set as an outcome. In other words, each term in the level 1 model has its own regression equation at level 2, which can include both an intercept and a residual (random effect). The random effects at the higher levels in the model (u_ij) can also be fixed at 0, which forces the effect to stay constant across all level 2 units, as with single-level regression. Indeed, if all random effects at the higher levels were fixed to 0 then the equation simplifies to a single-level regression equation. Thus, the entire basis of HLM lies in the random effects at the higher levels. For each of these variables researchers have to determine whether it makes theoretical sense to include the random effect for the term or not. If there is no reason to believe that any of the effects will vary at the higher levels – including the intercept and all predictor variables – then HLM may not be warranted. However, as we will see later we can also use the null model in Equation 2.1 to test for the degree of dependence upon the higher levels by estimating the intraclass correlation coefficient. Now that the model has become more complex it is also critical that we pay close attention to subscripts so we can recognize what each term is referencing. In a two-level model each term has two subscripts, the first of which corresponds to level 1 while the second refers to level 2. For each subscript, 0 refers to an intercept, while all other numbers simply represent a sequential count of predictor variables added to the model. This can quickly become confusing, as γ_00, γ_01, γ_10, and γ_11 all refer to different parameters. With practice, however, it can eventually become second nature. For example, γ_00 is the overall intercept in the model, as there are no predictor variables included. The γ_10 term represents the coefficient for the first predictor at level 1, while γ_01 refers to the first level 2 predictor variable of the level 1 intercept (i.e., 0 predictors at level 1). The γ_11 is slightly more complicated, as it is the first level 2 predictor of the first level 1 predictor. For example, γ_11 may refer to the effect of a student with a disability (level 1 predictor) attending a private school (level 2 predictor) on the student’s achievement (outcome). We can, of course, also display Equation 2.4 in its mixed model form by substituting the terms from level 2 into level 1, as follows: Equation 2.4 is defined as Y_ij=β_0j+β_1j X_ij+r_ij β_0j=γ_00+γ_01 W_j+u_0j β_1j=γ_10+γ_11 W_j+u_1j Substitute in γ_00+γ_01 W_j+u_0j for β_(0j ) Y_ij=γ_00+γ_01 W_j+u_0j+β_1j X_ij+r_ij β_1j=γ_10+γ_11 W_j+u_1j Substitute in γ_10+γ_11 W_j+u_1j for β_1j Y_ij=γ_00+γ_01 W_j+u_0j+(γ_10+γ_11 W_j+u_1j)X_ij+r_ij Redistribute Y_ij=γ_00+γ_01 W_j+u_0j+γ_10 X_ij+γ_11 W_j X_ij+u_1j X_ij+r_ij By convention, the terms are generally rearranged so that the fixed effects appear first, followed by the random effects, which leads us to our final mixed model, defined as Y_ij=γ_00+γ_10 X_ij+γ_01 W_j+γ_11 W_j X_ij+u_0j+u_1j X_ij+r_ij (2.5) As predictor variables are added to the model it can quickly become quite complex. Paying close attention to the subscripts can help make the structure of the model clear so you can better understand whether the model makes theoretical sense, and what relationships specifically the researcher is testing. Going back to our example with math, we may theorize specific predictor variables that affect student achievement at both the individual student level and the school level. For example, we may hypothesize that students’ eligible for free or reduced price lunch (FRL) may have significantly different math achievement than students not eligible for FRL. We may further hypothesize that FRL has a school level effect – as in, students in schools with a high proportion of FRL eligibility may have significantly different math achievement than students attending low proportion FRL eligible schools, independent of their own FRL status. Equation 2.4 then becomes 〖Math〗_ij=β_0j+β_1j 〖FRL〗_ij+r_ij (2.6) β_0j=γ_00+γ_01 〖AverageFRL〗_j+u_0j β_1j=γ_10+γ_11 〖AverageFRL〗_j+u_1j There are a few important aspects to highlight in equation 2.6 corresponding to the underlying theory. First, the level 1 model is quite basic, simply stating that the math achievement of students depends, in part, upon their FRL status. The level 2 model, however, is a bit more complex. First, the model states that a student’s intercept depends, in part, upon the average FRL – or the proportion of FRL eligible students – in the school the student attends. This effect is specified to vary randomly across schools. But perhaps even more complex, the model states that the effect of an individual’s FRL status upon his or her math achievement depends, in part, upon the average FRL of the school the student attends (the γ_11 term). This effect is similarly specified to vary randomly across schools. "],
["model-building.html", "3.1 Model building", " 3.1 Model building When building HLM models the researcher generally begins with a null, or empty model. Predictors are then added to the model in a forward or backward elimination approach. The overall fit of the model must also be considered throughout the model building process. Below, each of these issues is discussed in turn. Null model. For a basic two-level model, the null model is defined simply by Equation 2.1. The model is equivalent to a one-way analysis of variance (ANOVA) and is used within an HLM framework primarily to establish a baseline model from which subsequent models can be compared, and to capture the degree to which variance at level 1 depends upon group membership at level 2. Dependence at the higher levels can be assessed through the intraclass correlation coefficient (ICC), defined as ρ=τ_00/((σ^2+τ_00 ) ) (2.7) where, ρ = the ICC, τ_00=u_0j= variance at level 2 σ^2=r_ij= variance at level 1 The ICC ranges from 0 to 1.0 and describes the proportion of the total variance that depends upon group membership. Although not discussed yet, it is worth mentioning here that the ICC for three level models is calculated similarly, but simply includes the variance term for the third level in the denominator. The ICC can then be calculated for level 2, with τ_00 in the numerator, or for level 3 with τ_000 in the numerator. Some (e.g., Lee, 2000) suggest interpreting the ICC as a means for determining whether HLM is warranted, or whether standard single-level regression would suffice. For example, if there is a small amount of dependence on the higher-level groupings then the independence of observations assumption of single-level regression may not be violated, and thus may be an appropriate technique. Yet, as Roberts (2007) suggests, small ICCs may not warrant abandoning HLM given that additional dependence can arise after predictors have been entered into the model. The ICC, therefore, should be an initial indicator of the warrants of HLM, but small values should not immediately rule out its use. Entering predictor variables. Predictor variables can be entered into an HLM analysis through a forward, backward elimination, or simultaneous “block-entry” approach. The choice of how to include predictors into the model often depends upon the a priori assumption about the relations between predictor variable (i.e., how they interact) and the overall purpose of the analysis. For example, if a researcher were including variables in a model that theoretically interacted in a meaningful way, he or she would likely want to enter both variables into the model simultaneously (along with, potentially, their interaction term). However, if the researcher was interested in the unique contribution of each predictor, independent of the other predictors in the model, then he or she would likely want to enter each predictor sequentially, examining the model fit between each subsequent model. Further, a researcher may be interested in, for instance, examining the effect of a specific predictor after a host of demographic variables have been controlled for. In this case, the researcher would enter all the demographic variables into the model (first block), run the analysis, then enter the predictor variable of interest in the model and rerun the analysis, testing for differences in model fit between the two models. 3.1.1 Centering Perhaps more important than sequential or simultaneous entering of predictors, however, is the choice of centering. Variables can generally be entered into the model in three ways: uncentered, group centered, or grand-mean centered. The choice of centering changes the interpretation of the intercept, and improper centering can result in model misspecification and untrustworthy results. Centering is necessary whenever a variable does not have a true zero point. Just as with standard regression, the intercept represents the value on the dependent variable when all predictor variables are 0. When a variable does not have a true zero point, the variable must be transformed or centered so that it does. For instance, scores on the SAT math test range from 200-800. Prior to analysis, 200 points from each score could be subtracted so the variable would have a true zero point, and the scale would range from 0-600. When variables are entered uncentered, or a transformation such as that described above is used prior to the analysis, the variable maintains (roughly) its original scale. That is, the intercept represents the average score on the dependent variable for students with a 0 (or a transformed 0, i.e., 200 on the example above) on the predictor variable. Alternatively, the SAT variable could be entered group or grand-mean centered. Group centering refers to subtracting the average score from the higher-level group (e.g., school) for all students within said group. Thus, variables can only be entered group centered at the lower levels of the model, and not at the highest level. Group-centering also changes the model as a whole. That is, group-centering is not simply a linear transformation of the variable. The model fit overall will change when group-mean centering is used (Hox, 2010). When variables are entered group centered the intercept then represent the average score for the group for which the student is a member. Finally, at any level variables can be entered grand-mean centered by subtracting the overall grand-mean (mean for the variable across all units) from each score. Grand-mean centering is a simple linear transformation of students’ scores, and the model-fit is not changed. When variables are entered grand-mean centered the intercept represents the average score on the dependent variable for all individuals in the dataset. Differences in variable centering methods are important given that they change the interpretation of the intercept, and, potentially, the model overall. But centering can also have some additional benefits, such as reducing issues of multicollinearity, which can ease estimation. Once variables have been entered into the model, we can estimate a “pseudo R2” statistic. Unfortunately, there is no direct measure of the variance accounted for by HLM models – hence the name “pseudo”. Pseudo R2 statistics provide an indication of the amount of variance accounted for by comparing the variance component in an unconditional model to the same variance component in a conditional model. Pseudo R2 can be calculated for the overall residual in the model, r_ij, or for any random parameter in the model (e.g., intercept variance). Pseudo R2 is calculated by applying the following formula: Pseudo R2 =((σ_unconditional2-σ_conditional2))/(σ_unconditional^2 ) (2.8) Applying Equation 2.8 provides an estimate of the proportional reduction in unexplained variance in the random parameter, accounted for by the predictor variables in the model. When exploring how predictor variables account for the variance in specific parameters, one would simply substitute the σ^2 terms for τ’s. Model fit. The primary fit statistic used in HLM analyses is the deviance statistic. The deviance statistic is equal to -2 * the natural log of the likelihood ratio. Note that the actual computation of the deviance statistic is based on the maximum likelihood estimation procedure (and thus can only be computed when maximum likelihood estimation is used), which is beyond the scope of this paper. However, it is worth noting that the deviance statistic is an incremental fit indicator, by which its values are only meaningful relative to the values obtained from other models. Yet, to compare the deviance between models, they must also be nested – meaning that one model could be constructed from the other by simply including or eliminating predictor variables. So, for instance, the deviance from a two-level model cannot be compared to the deviance from a three-level model, or a two-level model with a different outcome. Part of the reason that we always begin model building with an unconditional, or null model – is so that we have a baseline from which to compare the deviance statistic to for subsequent nested models. In general, the researcher begins by examining the deviance statistic from the null model. Predictors are then entered at level 1, and the deviance for these conditional models are compared relative to the null model. Once a level 1 model has be “settled” upon, the researcher then proceeds to enter predictors at level 2, using the deviance from the final level 1 model for subsequent model fit comparisons. If the model includes more than two levels then the researcher continues this process until a final model is established (i.e., comparing the deviance from models with predictors at level 3 with the final level 2 model). Deviance represents “lack of fit”, with larger values indicating a poorer fitting model. The fit between two models can be statistically tested. The procedure is quite simple, given that the difference between two deviance statistics follows a chi-square distribution, with the degrees of freedom equal to the difference in the number of parameters estimated in the two models. If the resulting value is significant, then the model with the lower deviance value fits the data significantly better. Evaluating model fit can, at times, be a bit confusing given that individual coefficients added to the model may be significant, but the overall difference in model fit may not be significant. Theory, of course, should always guide decisions about subsequent steps in model building, but generally if the overall model does not fit significantly better, then parsimony would dictate the removal of the predictor variable in the more complex model, despite its significance. Finally, I would be remiss if I failed to mention some of the underlying assumptions of HLM, which should be thoroughly evaluated before any results are interpreted. There are, in general, six assumptions related to HLM – three concerning the error structure, and three concerning the predictor variables. These assumptions are outlined in Table 2.1 below. Table 2.1 HLM Model Assumptions Error structure assumptions Predictor variable assumptions Independent and normally distributed level 1 residuals, with a mean of 0 and common variance, σ^2. Level 1 predictors independent of level 1 residuals Independent random effects at higher levels (i.e., level 2 &amp; level 3), multivariate normally distributed, with a mean of 0 and a common variance, τ^2. Higher level predictors independent of the residuals at the corresponding level Residuals between levels are independent (i.e., no covariance between residuals at different levels). Predictors at each level are independent of the random effects at other levels While the researchers may not explicitly discuss model assumptions within a research paper, they should, at minimum, provide the reader with assurances that assumptions were investigated and that no major violations were found (perhaps through a footnote). "],
["illustrated-example-1-two-level-model.html", "3.2 Illustrated Example 1: Two-Level Model", " 3.2 Illustrated Example 1: Two-Level Model We will now move from discussing HLM from an abstract, theoretical position, to illustrating the technique through a series of concrete examples. We will begin by analyzing cross-sectional data in two ways - first with a single-level multiple regression analysis, then with a two-level HLM analysis. The analyses are conducted with the same dataset, and include students’ specific disability type as a predictor of their state alternate assessment score for mathematics. The analyses are identical, with the exception of the HLM model accounting for the nesting of students within schools. Tables 2.3 and 2.4, below, illustrate the differences between the two models. Data for these analyses came from a sample of 288 students who had a severe cognitive disability, were enrolled in fifth grade, and took the math portion of one state’s alternate assessment during the 2010-2011 school year. All students were identified as having one of seven specific disabilities: (a) intellectual disability, (b) communication disorder, (c) emotionally disturbed, (d) orthopedic impairment, (e) other health impairment, (f) autism spectrum disorder, or (g) learning disabled. The referent group for both analyses was students with a learning disability. Table 2.2 displays descriptive statistics for each variable. Table 2.2 Descriptive Statistics: Example 1 Variable N Mean Standard deviation Intellectual disability (ID) 77 .27 .44 Communication disorder (ComDis) 36 .13 .33 Emotionally disturbed (ED) 8 .03 .16 Orthopedic impairment (OI) 13 .05 .21 Other health impairment (OHI) 35 .13 .33 Autism spectrum disorder (Aut) 62 .22 .41 Learning disabled (LD)* 57 .20 .40 Students’ scores on the state alternate assessment (MthRIT) 288 97.87 15.17 *Referent group For both analyses, MthRIT represented students’ scores on the math portion of the alternate assessment. All disability variables were dummy-coded vectors, coded 1 if the student had the disability, and 0 otherwise. Table 2.3 displays the results from the single-level multiple regression analysis. Table 2.3 Single-Level Regression Results: Example 1 Variable Unstandardized coefficients Standardized coefficients Correlations 95% Confidence interval b SE β t p Zero-order Semi-partial Lower bound Upper bound Intercept 108.75 1.73 62.93* .00 105.35 112.15 ID -15.93 2.28 -.47 -6.99* .00 -.20 -.39 -20.42 -11.44 ComDis -3.37 2.78 -.07 -1.21 .23 .19 -.07 -8.84 2.10 ED -1.82 4.93 -.02 -.37 .71 .10 -.02 -11.52 7.88 OI -27.49 4.01 -.38 -6.85* .00 -.24 -.38 -35.38 -19.59 OHI -8.64 2.80 -.19 -3.08* .00 .06 -.18 -14.16 -3.13 Aut -17.89 2.39 -.49 -7.47* .00 -.24 -.41 -22.60 -13.18 * p &lt; .05 The results of the model suggest that approximately 21 percent of the variance in alternate assessment scores was accounted for by students’ disability category (R2 = .21). Because students with LD were entered as the referent group, the intercept of the regression equation represents the average test score for students with LD on the state alternate assessment for math (108.75), as shown in the column labeled b of Table 2.3. Below the intercept, the effect of each predictor variable (student disability type) is reported. For example, students with an intellectual disability scored, on average, 15.93 points lower than students with LD. Similarly, students with autism spectrum disorder scored, on average, 17.89 points lower than students with LD. All predictor variables were significant (p &lt; .05), with the exception of students identified with an emotional disturbance or communication disabled. When conducting the HLM analyses, we began by specifying the unconditional, or null model, by specifying MthRIT as the outcome variable in Equation 2.1 to get 〖MthRIT〗_ij=β_0j+r_ij (2.9) β_0j=γ_00+u_0j This model was, again, defined primarily to (a) evaluate the degree to which MthRIT scores depend upon the school the student was nested within, and (b) provide a baseline deviance statistic from which subsequent models could be compared. The results of the model displayed in Equation 2.9 are displayed in Table 2.4 as Model 1. The level 1 variance (σ2) was 112.28, and the level 2 variance (τ00) was 115.25. Plugging these numbers into Equation 2.7, we get ρ=115.25/(115.25+112.28) = .5065 (2.10) which equals the proportion of variance that lies between schools. Thus approximately 50.65% of the variance in MthRIT scores depended upon the school students attended (note: this is an unusually high number). The model had 2 estimated parameters, with deviance = 2246.932195. The next step in model building process was to add predictor variables at level 1. For this model, it would make little sense to enter the predictor variables separately given that they were a set of dummy-coded vectors. That is, the set of variables together represent a single theoretical construct (disability). Thus, all variables were entered into the model simultaneously, as 〖MthRIT〗_ij=β_0j+β_1j (〖MR〗_ij )+β_2j (〖ComDis〗_ij )+β_3j (〖ED〗_ij )+β_4j (〖OI〗_ij )+β_5j (〖OHI〗_ij )+β_6j (〖Aut〗_ij )+r_ij (2.11) β_0j=γ_00+u_0j β_1j=γ_10 β_2j=γ_20 β_3j=γ_30 β_4j=γ_40 β_5j=γ_50 β_6j=γ_60 Note that the only difference between Equation 2.11 and the single-level model is the random effect u_0j on the intercept, allowing the term to vary by school. The results of the model shown in Equation 2.11 are displayed in Table 2.4 below as Model 2. Unfortunately, we cannot test for statistical significance in the difference between the deviance statistics between Model 1 and Model 2 because there were not sufficient degrees of freedom. However, as shown in Table 2.4, the deviance statistic does reduce noticeably. We can also explore the proportional reduction in unexplained variance by applying Equation 2.8, as follows Pseudo R2 =((112.28127-101.33984))/112.28127=0.097 (2.12) Thus, the inclusion of students’ disabilities reduced the unexplained variance by approximately 10%. Similarly, we can explore the variance in the intercept accounted for by the predictors by Pseudo R2 =((115.25220-76.50049))/115.25220=0.336 (2.13) which leads us to determine that students disability accounts for approximately 33.6% of the variance in students’ intercepts. Notice that all the values within Equations 2.12 and 2.13 can be found in Table 2.4. The values are simply carried out to more decimal places in the equations. If, for some reason, we hypothesized that the effect of a specific disability type on MthRIT depended on the school the student attended, we could simply estimate the corresponding random effects, as displayed in Equation 2.14. 〖MthRIT〗_ij=β_0j+β_1j (〖MR〗_ij )+β_2j (〖ComDis〗_ij )+β_3j (〖ED〗_ij )+β_4j (〖OI〗_ij )+β_5j (〖OHI〗_ij )+β_6j (〖Aut〗_ij )+r_ij (2.14) β_0j=γ_00+u_0j β_1j=γ_10+u_1j β_2j=γ_20+u_2j β_3j=γ_30+u_3j β_4j=γ_40+u_4j β_5j=γ_50+u_5j β_6j=γ_60+u_6j Again, because the set of dummy-coded variables represent a single theoretical entity, it would make most sense to estimate all the random effects or none of the random effects. The results of Equation 2.14 are displayed as Model 3 in Table 2.4. Table 2.4 HLM Results: Example 1 Fixed Effects Model 1 Model 2 Model 3 Intercept, γ_00 97.76** 105.55** 108.68 ID, γ_10 - -11.21 -15.89 ComDis, γ_20 - -4.34 -3.60 ED, γ_30 - -2.51* -2.00 OI, γ_40 - -18.24 -15.43 OHI, γ_50 - -6.22 -9.49 AUT, γ_60 - -11.60 -14.32 Variance Components (Random Effects) Within-student, r_ij 112.28 101.34 68.51 Intercept, u_0j 115.25 76.50** 0.17 ID, u_1j - - 143.72 ComDis, u_2j - - 0.85 ED, u_3j - - 0.17 OI, u_4j - - 328.08 OHI, u_5j - - 99.35 AUT, u_6j - - 176.11 Deviance 2246.93 2181.25 2126.61 **p &lt; .01, *p &lt; .05 There are a couple of things to note about the HLM results. First, thus far only the results for models with predictors at level 1 (note the 0 in the second subscript in the fixed effects notation) have been presented. Second, although Model 3 technically fits the data the best, as it has the lowest deviance statistic, it displays some odd results. For example, the variance component values are both very high and very low, depending on the variable. Further, none of these values are statistically significant – suggesting the effect of student disability does not depend on school. Finally, Model 3 is perhaps less theoretically plausible than Model 2. That is, one would expect the effect of a specific disability type to be largely invariant across schools, and not depend upon school membership, given that it is a trait of the student. While instruction occurring within the school may influence this relationship, that instruction is mostly accounted for by the random intercept term. If we consider Model 2 our final model, and compare the HLM results in Table 2.4 to our single-level results in Table 2.3, we can see some important differences. The intercept is approximately 3 points lower, while the magnitude of the effects of intellectual disability, orthopedic impairment, other health impairment, and autism are all markedly reduced. The effects of all remaining disability variables, however, actually increase in magnitude. These differences arise purely by accounting for the nesting of students within schools. Although we conclude the discussion of cross-sectional data here, it is also important to highlight that any number of school-level predictors could be added to the model at level 2. These variables could be entered as a predictor of the intercept or any of the level 1 predictors – analogous to a cross-level interaction (which is evident when examining the full mixed model equation). For example, we may hypothesize that students’ MthRIT score depends upon the size of the school. A school size variable could then be entered as a predictor of the level 1 intercept as γ_01 (Size). If we theorized that, for some reason, the effect of a students’ disability – say ED – on MthRIT depended on school size, we could easily model the interaction with γ_31 (Size). Note how the subscripts change between these variables. In both cases Size is the first level 2 predictor (second subscript), but in the first example Size is a predictor of the intercept (i.e., 0 predictors in the model) and in the second example Size is a predictor of the third level 1 predictor, ED. Thus, the flexibility in the types of relations HLM allows researchers to model is tremendous. "]
]
